# üèÄ Projeto de Predi√ß√£o de Arremessos - Kobe Bryant

## Este projeto aplica t√©cnicas de Machine Learning para prever se um arremesso feito por Kobe Bryant durante sua carreira resultou em cesta ou n√£o.

## üõ†Ô∏è Tecnologias Utilizadas
- üêç Python
- üìä Scikit-learn
- üß™ PyCaret
- üöÄ MLFlow
- üìà Streamlit
  <p align="center">
  <img src="https://img.shields.io/badge/Kaggle-20BEFF?style=for-the-badge&logo=Kaggle&logoColor=white" />
  <img src="https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=Streamlit&logoColor=white" />
  <img src="https://img.shields.io/badge/scikit_learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white" />
  <img src="https://img.shields.io/badge/Python-FFD43B?style=for-the-badge&logo=python&logoColor=blue" />
  <img src="https://img.shields.io/badge/VSCode-0078D4?style=for-the-badge&logo=visual%20studio%20code&logoColor=white" />
  <img src="https://img.shields.io/badge/Colab-F9AB00?style=for-the-badge&logo=googlecolab&color=525252" />
</p>

## üîÅ Como Rodar o Projeto
  1. Clone o Reposit√≥rio

         git clone https://github.com/acrisandradee/ArremessosKobe.git

      
  2. Ative o ambiente virtual
     
             python -m venv .venv
             source .venv/bin/activate  # Linux/macOS
             .venv\Scripts\activate   # Windows

  3. Instale as depend√™ncias do projeto

          pip install -r requirements.txt
 
      
  4. Execute as pipelines com Kedro
     
    kedro run --pipeline=PreparacaoDados
    kedro run --pipeline=treinamento
    kedro run --pipeline=aplicacao

5. Execute o MLFlow
   
        Mlflow ui

6. Execute o Dashboard no Streamlit
   
        streamlit run dashboard/app.py
   
![image](https://github.com/user-attachments/assets/5994f80b-d5d8-4a4b-9830-931c688c1ae4)


# üí° Como as Ferramentas Auxiliam no Pipeline

## Streamlit
  - O Streamlit criou um dashboard interativo para simulacao de arremessos, permitindo o monitoramento do modelo com visualizacoes graficas.
![image](https://github.com/user-attachments/assets/33fa7c91-4780-445f-bc17-c412c4b09db2)

 ## MLFlow
 - O Mlflow foi essencial para acompanhar todas etapas do ciclo de vida do modelo. Durante os experimentos ele registrou as metricas,parametros utilizados e os modelos gerados.
 - O modelo final foi registrado como ModeloArremessoKobe@prod, permitindo que ele fosse facilmente acessado e reutilizado. Quando necess√°rio, o modelo pode ser atualizado com novas vers√µes, mantendo o hist√≥rico completo no Model Registry.
 -  Al√©m disso, o MLflow tamb√©m foi usado para monitorar o desempenho do modelo em producoes, com o registro de metricas como F1 Score e Log Loss, garantindo visibilidade sobre a sa√∫de do modelo em tempo real.
![image](https://github.com/user-attachments/assets/7b0e8487-b4f0-445d-8780-92a3129a876f)


## Pycaret
-O PyCaret facilitou o treinamento dos modelos ao automatizar tarefas como normaliza√ß√£o dos dados, balanceamento das classes e sele√ß√£o das vari√°veis mais relevantes.
-  Al√©m disso, ele permitiu testar e comparar diferentes algoritmos de forma r√°pida, com avalia√ß√£o baseada em metricas como F1 Score e Log Loss, facilitando a escolha do modelo com melhor desempenho.

![image](https://github.com/user-attachments/assets/22d9ca26-36f1-483f-aed8-158bb507173f)

## Scikit-Learn
- O Scikit-Learn serviu como base para algoritimos usados como a regressao logistica e a arvore de decisao. mesmo usado com o PyCaret, ele garantiu estabilidade, desempenho e compatibilidade com o MLflow, permitindo que os modelos fossem treinados, avaliados e salvos.

 ![image](https://github.com/user-attachments/assets/8ddbeb41-0bc1-4de0-a834-db7c63487b25)
 
# üìÅ Artefatos que foram gerados 
| Etapa do Pipeline           | Artefato                          | Caminho                          | Descri√ß√£o detalhada |
|----------------------------|-----------------------------------|----------------------------------|----------------------|
| Coleta (dados brutos)      | dataset_kobe_dev.parquet          | data/01_raw/                     | Dados hist√≥ricos de arremessos realizados por Kobe Bryant com m√∫ltiplas vari√°veis.   |
| Coleta (dados de produ√ß√£o) | dataset_kobe_prod.parquet         | data/01_raw/                     | Dados de arremessos simulados para aplica√ß√£o em produ√ß√£o, com mesma estrutura da base de desenvolvimento. |
| Prepara√ß√£o dos dados       | data_filtered.parquet             | data/02_intermediate/            | Dados filtrados contendo apenas as colunas relevantes e sem valores nulos. Base pronta para modelagem. |
| Separa√ß√£o treino/teste     | base_train.parquet                | data/processed/                  | Subconjunto com 80% dos dados usados para treinar os modelos, com estratifica√ß√£o da vari√°vel alvo. |
| Separa√ß√£o treino/teste     | base_test.parquet                 | data/processed/                  | Subconjunto com 20% dos dados usados para avaliar o desempenho dos modelos treinados. |
| Treinamento do modelo      | modelo_vencedor/ (pasta com pkl)  | data/06_models/                  | Modelo final salvo com estrutura MLflow (inclui model.pkl, MLmodel, conda.yaml, requirements.txt). |
| Aplica√ß√£o em produ√ß√£o      | predicoes_prod.parquet            | data/07_model_output/            | Resultado da predi√ß√£o sobre a base de produ√ß√£o com as colunas `score` e `shot_made_flag_predito`. |
| Visualiza√ß√£o / Dashboard   | previsoes_producao.parquet        | data/08_reporting/               | Dados de predi√ß√µes formatados para uso no dashboard de monitoramento com Streamlit. |

![image](https://github.com/user-attachments/assets/0aa0cbc9-e510-4965-9607-7f17a28f0596)


## üîçObservacao sobre o modelo na nova base
- Observei que ha diferencas entre a base de treino principalmente arremessos curtos e a base de produ√ß√£o erremessos de 3 pontos. Essa diferen√ßa na distribui√ß√£o foi evidenciada via histogramas comparativos, e impactou diretamente a performance em produ√ß√£o.
- Exemplo: F1 Score caiu de 0.72 para pr√≥ximo de zero em testes anteriores.

  ![image](https://github.com/user-attachments/assets/e65b0a21-b11d-41a4-9f9a-94132bb7ccbc)

# üìä Monitoramento da Sa√∫de do Modelo

## Com a variavel resposta
Quando temos a informa√ß√£o se o arremesso foi certo ou errado (shot_made_flag), podemos:

- C√°lcular  m√©tricas como F1 Score e Log Loss
- Comparar valores reais e preditos, permitindo detectar erros e padr√µes de desempenho
- Identificar mudan√ßas no comportamento dos dados com o tempo 

## Sem a variavel resposta
Quando n√£o sabemos se o arremesso foi acertado:

- Analisamos a distribui√ß√£o dos scores (confian√ßa nas previs√µes) para ver se o modelo continua coerente
- Usamos dashboards e logs para acompanhar como o modelo est√° se comportando

# üîÅ Estrat√©gias de Retreinamento do Modelo
## Estrategia Reativa
Essa abordagem e usada quando observamos uma queda significativa nas m√©tricas de desempenho, como F1 Score ou Log Loss.
- tipo se o modelo comecar a erra muito nos arremessos
- Entao coletamos novos dados rotulados, atualizamos a base de treino e reexecutamos o pipeline para gerar uma nova vers√£o do modelo.

  ## Estrategia Preditiva
  Neste o retreinamento √© feito de forma peri√≥dica ou autom√°tica, mesmo que o modelo ainda esteja performando bem.
  - Atualizamos o modelo a cada epoca com dados mais recentes
  -  ou pipeline pode ser agendado para incluir novos dados. reavaliar a performance e se estiver melhor, publicar uma nova vers√£o no MLflow Registry.

  
 
---

<div align="center">

‚ú® Desenvolvido por **Cristina Andrade** ‚Äì 2025  
   Projeto de **Engenharia de Machine Learning** baseado no Framework TDSP (Microsoft)  
   Da ideia ao deploy com **Kedro**, **PyCaret**, **MLflow** e **Streamlit**

</div>

  

